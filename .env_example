# Docker Compose
CONFLUENT_PLATFORM_VERSION="7.6.0"
PLATFORM="linux/arm64"
HOST="localhost"
CONFLUENT_POSTGRES_CDC_VERSION="2.5.4"
POSTGRESQL_VERSION="14"
# Configuration files
KAFKA_CONFIG="config/docker_host.ini"
# DB Provisioning
FLAG_FILE=".db_provisioning.flag"
MD5_PASSWORD_SALT="<MD5_string_here>"               # String to be used to salt hash passwords
CLIENT_DB_PROVISIONING="chatbot-db_provisioning"
# Web App (Chatbot front-end)
WEBAPP_HOST="0.0.0.0"
WEBAPP_PORT=8888
CLIENT_ID_WEBAPP="chatbot-webapp"
TIMEOUT_SECONDS=120
# Consumer to VectorDB
CLIENT_ID_VDB="vdb-app"
# Chatbot back-end
CLIENT_ID_CHATBOT="chatbot-app"
LLM_ENGINE="openai"                             # Options: openai (paid), groq (free), bedrock (AWS: paid)
AWS_API_KEY=" <access_key>:<secret_access_key>" # Required if LLM_ENGINE=bedrock (format: <access_key>:<secret_access_key>)
AWS_REGION="<aws_region>"                       # Required if LLM_ENGINE=bedrock
OPENAI_API_KEY="<Your_OpenAI_API_Key_Here>"     # Required if LLM_ENGINE=openai (Get the API Key here: https://platform.openai.com/docs/quickstart/account-setup)
GROQ_API_KEY="<Your_GroqCloud_API_Key_Here>"    # Required if LLM_ENGINE=groq (Get the API Key here: https://console.groq.com)
BASE_MODEL="gpt-3.5-turbo-0125"                 # Any valid model, example: gpt-3.5-turbo-0125 (if LLM_ENGINE=openai), mixtral-8x7b-32768 (if LLM_ENGINE=groq), amazon.titan-text-express-v1 or amazon.titan-text-premier-v1:0 (if LLM_ENGINE=bedrock)
MODEL_TEMPERATURE=0.3
VECTOR_DB_MIN_SCORE=0.3
VECTOR_DB_SEARCH_LIMIT=2